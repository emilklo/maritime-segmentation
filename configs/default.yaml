# RF-DETR-Seg Training Config for LaRS Maritime Dataset
# Fine-tuning best practices applied

# Model
model:
  name: "rf-detr-seg-preview"

# Data
data:
  dataset_dir: "data/lars_rfdetr"  # RF-DETR format (prepared by scripts/prepare_lars.py)
  input_size: 560  # Must be divisible by 56 for RF-DETR (560, 616, 672, etc.)
  batch_size: 4
  num_workers: 4

# Training
training:
  epochs: 50
  lr: 5.0e-5              # Lower LR for fine-tuning (was 1e-4)
  lr_encoder: 7.5e-5      # Encoder LR = 1.5x base (RF-DETR default ratio)
  weight_decay: 1.0e-4
  grad_accum_steps: 4     # Effective batch size = 4 * 4 = 16

  # Warmup & scheduling
  warmup_epochs: 2        # Stabilize early training
  lr_drop: 40             # Drop LR at epoch 40

  # Regularization (important for small dataset)
  drop_path: 0.1          # Stochastic depth regularization

  # Early stopping
  early_stopping: true
  early_stopping_patience: 10
  early_stopping_min_delta: 0.001

# Checkpoints
checkpoints:
  dir: "checkpoints"
  save_every_n_epochs: 5

# Logging
logging:
  project: "maritime-segmentation"
  wandb: false
  tensorboard: true
